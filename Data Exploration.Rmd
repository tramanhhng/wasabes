---
title: "Indoor Positioning Data Exploration"
author: "STAT4/510 Wasabees Group"
date: "2023-11-30"
output: pdf_document
---

1. Describe your data
2. Describe the basic variable component of your data
3. Report the various findings you have established so far, with interpretation (include discussion on what you find and add how useful it is to your project objective)
4. Discuss any challenges you encountered, and ways by which you handled these.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(kableExtra)
library(tidyverse)
```

# 1. Introduction - Data Description

Indoor position systems (IPS) development is an active area of research that can be used in numerous settings. Part of efforts to develop, calibration and model these systems are achieved through the use of WIFI signals. The following report, describes and characterizes a large data set compiled in a 15 by 36 meter area that contains six (wifi routers) access points, signal strength, various locations and orientation of the devices (10 parameters total)
The data is subdivided in two sub-sets, one denominated "offline data", which corresponds to various testing devices connected to the network at different locations and orientations, and the other an "online data", where 60 locations and orientations of the devices were selected at random.

The offline data was collected designing a 1 meter resolution grid, resulting in 166 locations. In each of these locations, the device was oriented starting at 0 degrees inclination and at 45 degrees increments, and the strength signal measured. Furthermore, each combination of location/orientation was sampled 110 times. This grid sampling is intended to be used to calibrate a indoor positioning model. On the other hand, the online data was designed to simulate real-world data, in which locations are not bounded by the 1 meter grid used in the offline data, and were selected at random. This randomization included the orientation of the device and therefore, the online data consists of 60 randomly selected location/orientation combinations sampled 110 times. 

More details of the floor plan, and location of online and offline data can be seen in Figure 1.

For simplicity, this report will share the results found in the offline dataset, but initial process of data cleaning can be directly applied to the online data as well. The online and offline data sets share the same structure so that's why in this document, we explore the offline data set with the expectation to apply the same method for the online data set.

```{r fig.align = "center", fig.cap= 'Flooplan location. Access points are squares. Grey dots are offline data locations and black dots are online data locations.'}
knitr::include_graphics("data/floorplan.jpg")
```


Circles serve as markers for the positions where "offline" measurements were conducted, while black squares indicate the locations of six access points. These reference positions provide a calibration of signal strengths within the building, forming the basis for constructing a model to predict the whereabouts of a hand-held device when its location is unknown. The hand-held device supplies x and y coordinates, akin to latitude and longitude on a map, along with its orientation. Signal strengths are recorded at eight orientations in 45-degree intervals. For every location and orientation combination, 110 signal strength measurements were documented for each of the six access points.


# 2. Data Processing

In this section, we provide a brief description of steps undertaken to format and clean the data set.

## 2.1 Variable Description

According to documents provided by the client, the data contains the following variables:

* `time`: time in miliseconds. 

* `scanMac`: IP address of the scanning device. 

* `pos`: the 3-D coordination of the scanning device. 

* `orientation`: the scanning device's orientation. 

* `mac`: the IP address of the access points. 

* `signal`: signal strength in dBm. 

* `channel`: the channel frequency. 

* `type`: type of device (access point = 3, device in adhoc mode =1)  

## 2.2 Data Formatting


```{r read_offline_data}

#Read the offline data txt file, with each row in the txt file becoming a text string
raw_offline = readLines("Data/offline.final.trace.txt")
```


The data is stored in a .txt file. The first six rows of the data is printed below

```{r}
head(raw_offline)
```

Below are our observations that shaped our approach for data formatting:

* The first three rows, marked by the character #, provides information for the next batch of 110 readings. Similar rows like this re-appear multiple times in the data set.

* The data rows contains a series of variables and values, separated by semicolons. We performed a simple split using semicolon as the separator, and found that some variables, such as `pos` and `mac` are further subdivided. Each `pos` value corresponds to a set of x, y, and z coordination. Each `mac` value corresponds to readings of `signal`, `channel`, and `type` respectively. 

Since our model is supposed to rely on wifi signal strength to predict device location, we need to format our data so that each observation corresponds to one single `signal` value.

```{r data_explanation, comment = ''}

raw_offline[1:3]
toPrint = strsplit(raw_offline, "[;]")[[10]]
head(toPrint)

#kbl(toPrint, caption = "Raw Data Format") %>% kable_classic(full_width = F, html_font = "Cambria", font_size = 10)
```

To transfer the data into a dataframe, we performed the following operations:   

* We start by cleaning the rows with the "#" symbol. A total of 5312 rows are removed, resulting in 146,080 rows.  

* Second, we utilize semicolon, colon, and equal sign as separators for the different variables in each row and re-format the data so each row represents an observation of the variable signal strength.  

* Lastly, we bind all rows together to create a dataframe and enter the proper names for each variable.  

```{r split_one_line, eval = FALSE}

#Exploration, do not run or eval for the document!

#The code below took all the separation out of one line. We take line 1 as an example and our separators are ; , and =
separator = strsplit(clean_offline[1], "[; , =]") [[1]]
separator

#The code below takes the time, id, pos, and degree readings out of "line" and arrange them in a matrix
aa = separator[c(2,4,6,7,8,10)] %>% 
  matrix(ncol=6,byrow=TRUE)
aa

#The code below takes the mac, signal, channel, and device type reading out of "line" and arrange them in a matrix
bb= separator[-(1:10)] %>%
  matrix(ncol=4, byrow=TRUE)
bb

#After this, we can combine the two matrices into a data frame. Our unit of analysis is signal strength, which mean each signal strength value needs to be one single observation. So to combine the data, we need to duplicate `a` by the number of rows in `b`.

aaa = separator[c(2,4,6,7,8,10)] %>% 
  matrix(ncol=6,nrow=nrow(bb), byrow=TRUE)

cbind(aa,bb) %>% view()
```

```{r clean_#_rows, echo = FALSE, comment = ''}

# The code below removes all rows that start with #
clean_offline <- raw_offline[substr(raw_offline,start=1, stop=1) != "#"]
#After this code, clean_offline has 146,080 rows, less than the original 151,392 rows

#Create a clean_function to split each row into variables and put the variables into a matrix format
clean_function = function(raw_data){
  #check first element of the 2d array created -> row of observation
  separators = strsplit(raw_data, '[;=,]')[[1]]
  critical_val = 10
  if (length(separators) == critical_val)
    return (NULL)
  #separate variables related to the devices!
  devices = matrix(separators[-(1:10)], ncol = 4, byrow=TRUE)
  #only the ones that have info
  cbind(matrix(separators[c(2,4,6,7,8,10)], 
               nrow = nrow(devices), ncol = 6, byrow = TRUE), devices)
}

#Apply clean_function to the whole clean_offline dataset
clean_dataframe = lapply(clean_offline, clean_function)

#covnert list into dataframe -> we need the do.call function
clean_offline = as.data.frame(do.call(rbind, clean_dataframe))

#add names
names(clean_offline) = c("time", "scanMac", "posX", "posY", "posZ", "orientation", "mac", "signal", "channel", "type")
```

We provide the structure of our data frame, along with the first 3 observations below.

```{r}
clean_offline[1:3,]
```


## 2.3 Data Cleaning


Before further exploring and analyzing the data, we do a pre-exploration process, to assess if variables should be removed from the data set, and if conversions were required. The list below presents the operations we performed:

* We observe that some variables, such as `time`, `position`, `orientation`, `signal` and `channel`, should be converted to numerical for analysis.  

* We now focus on the `time` variable. According documents provided by the client, time is expressed in milliseconds from midnight on January 1st, 1970. We convert this time value to seconds and then designate the class of the time element to visualize the values as date-times in R. Additionally, we retain the more precise time information in 'rawTime' in case it becomes necessary for future analysis.

* Based on the documents received from the client, a value of 1 for the variable `type` corresponds to ad-hoc devices. However, for the development and testing of the IPS, we will utilize only the signals measured at fixed access points. We removed all rows that have `type` = 1. After this removal, the variable `type` has a value of 3 for all observations, so we eliminate the variable `type` from the data set. 


Table 1 provides our cleaned and formatted offline dataset.

```{r formatting_df, echo = FALSE}
#Turn some variables into numeric
numeric_var = c("time","posX","posY","posZ","orientation","signal", "channel")
clean_offline[numeric_var] = lapply(clean_offline[numeric_var],as.numeric)

#Add the raw time column for record keeping, turn the time column into seconds and formatted in y-m-d time.
clean_offline$rawtime = clean_offline$time
clean_offline$time = clean_offline$time/1000
class(clean_offline$time) = c("POSIXt","POSIXct")

#Keep access point devices only
OffLine = clean_offline[clean_offline$type == "3", ]
OffLine = OffLine[, "type" != names(OffLine)]


#check numerical data
mean_off = OffLine %>% select(posX, posY, posZ, orientation, signal)
mean_off_p = as.data.frame(colMeans(mean_off))

#kbl(mean_off_p, caption = "Mean values for numerical variables") %>% kable_classic(full_width = F, html_font = "Cambria", font_size = 10)


```

Table 2 provides a basic exploration of each variable and calculate the mean for the numerical variables (i.e., position, orientation, signal). We find that position-z, has a mean of zero. Further exploration shows that the variable has a value of zero for all the observations in the offline dataset. This seemingly anomalous value is due to the fact that all of the readings were taken on one floor of the building. We were tempted to delete the variable posZ; however, since it is a meaningful variable and we do not know, for now, if the online dataset has different posZ values, we will keep it for the current stage of our project.

```{r posZ}
#Let's keep posZ because it is a meaningful pos variable that could be in our model, and we don't know if the online dataset has other values for posZ.

#Check min,max andmean vals for posZ 
meanposZ = mean(OffLine$posZ)
maxposZ = max(OffLine$posZ)
minposZ = min(OffLine$posZ)
#plot min,max, mean vals for posZ
posZdf = data.frame(meanposZ, maxposZ, minposZ)  
#kbl(posZdf, caption = "Min, Max and Mean values for posZ") %>% kable_classic(full_width = F, html_font = "Cambria", font_size = 10)

# Set up a more visually appealing boxplot
boxplot(OffLine$posZ,
        col = "skyblue", main = "Distribution of Z-axis Position", ylab = "Z-axis Position"
)

abline(h = mean(OffLine$posZ), col = "red", lwd = 2)
legend("topright", legend = "Mean", col = "red", lwd = 2)
par(mar = c(5, 4, 4, 2) + 0.1)
grid()
axis(1, cex.axis = 0.8)
axis(2, cex.axis = 0.8)
```



```{r table, echo=FALSE}
kbl(head(OffLine), caption = "Clean Data with transformed variables") %>% kable_classic(full_width = F, html_font = "Cambria", font_size = 5)

kbl(mean_off_p, caption = "Mean values for numerical variables") %>% kable_classic(full_width = F, html_font = "Cambria", font_size = 10)

kbl(posZdf, caption = "Min, Max and Mean values for posZ") %>% kable_classic(full_width = F, html_font = "Cambria", font_size = 10)
```


# 3. Data exploration

If you remember, the observations for orientation were configured at intervals of 0 degrees, 45 degrees, 90 degrees, and so forth, resulting in more than eight values. To further examine the distribution of the 'orientation' variable, we will analyze it through an empirical cumulative distribution function (ECDF).

```{r}
# Plot the orientation of the measurement device
plot(ecdf(clean_offline$orientation))
plot(ecdf(OffLine$orientation))
```
From the plot, we observe a concentration of observations around 0, 45, 90 degrees, and so forth. However, there is evident dispersion in between, with instances like 47.5 degrees, 358.2 degrees, and so on. This diversity in values is not a drawback; in fact, it could be valuable in its current form. Alternatively, we could derive value by categorizing these values into bins to align with the original eight values. To implement this, we will develop a function.

# 4. Challenges 
