---
title: "Indoor Positioning Data Exploration"
author: "STAT4/510 Wasabees Group"
date: "2023-11-30"
output: pdf_document
---

1. Describe your data
2. Describe the basic variable component of your data
3. Report the various findings you have established so far, with interpretation (include discussion on what you find and add how useful it is to your project objective)
4. Discuss any challenges you encountered, and ways by which you handled these.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(tidyverse)
```

1. Introduction

Indoor position systems (IPS) development is an active area of research that can be used in numerous settings. Part of efforts to develop, calibration and model these systems are achieved through the use of WIFI signals. The following report, describes and characterizes a large data set compiled in a 15 by 36 meter area that contains six (wifi routers) access points, signal strength, various locations and orientation of the devices.
The data is subdivided in two sub-sets, one denominated "offline data", which corresponds to various testing devices connected to the network at different locations and orientations, and an "online data", where 60 locations and orientations of the devices were selected at random.

The offline data was collected designing a 1 meter resolution grid, resulting in 166 locations. In each of these locations, the device was oriented starting at 0 degrees inclination and at 45 degrees increments, and the strength signal measured. Furthermore, each combination of location/orientation was sampled 110 times. This grid sampling is intended to be used to calibrate a indoor positioning model. On the other hand, the online data was designed to simulate real-world data, in which locations are not bounded by the 1 meter grid used in the offline data, and were selected at random. This randomization included the orientation of the device and therefore, the online data consists of 60 randomly selected location/orientation combinations sampled 110 times. 

More details of the floor plan, and location of online and offline data can be seen in Figure 1.

For simplicity, this report will share the results found in the offline dataset, but initial process of data cleaning can be directly applied to the online data as well. 


![Figure 1: Flooplan location. Access points are squares. Grey dots are offline data locations and black dots are online data locations.](data/floorplan.jpg)


The format of the data is stored in a .txt file. Each location, and its subsequent 100 samples, is marked by the presence of a "#" symbol with three outputs.
The text bellow depicts the first 10 rows found in the dataset, note how the first 3 entries are marked by the hash symbol. Separations between samples are delimitated by ",1"

```{r echo = FALSE}
#Read the offline data txt file, with each row in the txt file becoming a text string
raw_offline = readLines("Data/offline.final.trace.txt")
```

```{r }

raw_offline[1:4]
#kbl(raw_offline[1:4], caption = "Table 1: Raw Data Examples", col.name = "") %>% 
#  kable_classic(full_width = F, html_font = "Cambria") %>% kable_styling()
#kbl(PC1_load, caption = "Loadings for PC1 (scaled)", col.names = c('Predictor', "Loading Value"))%>% kable_classic(full_width = F, html_font = "Cambria")

```




```{r clean_#_rows}

#The txt file contains multiple rows starting with # (for example, rows 1, 2, 3) which does not share the same structure as other rows. The code below gets rid of these rows.

clean_offline <- raw_offline[substr(raw_offline,start=1, stop=1) != "#"]
str(clean_offline)

#After this code, clean_offline has 146,080 rows, less than the original 151,392 rows
```


```{r split_line}
#In clean_offline, each row now has the same structure:
#Semicolons separate between variables
#Equal signs separate variable names and values
#For the signal readings, readings of the same access point are separated by commas

#The code below took all the separation out of one line (line 1)
line = strsplit(clean_offline[1], "[; , =]") [[1]]
line

#The code below takes the time, id, pos, and degree readings out of "line" and arrange them in a matrix
line[c(2,4,6,7,8,10)] %>% 
  matrix(ncol=6,byrow=TRUE) %>% view()

#The code below takes the mac, signal, frequency, and device type reading out of "line" and arrange them in a matrix
line[-(1:10)] %>%
  matrix(ncol=4, byrow=TRUE) %>% view()

#After this, we can combine the two matrices to create one row of data for our ideal data frame. 

#The code below attempts to put all the above operations in this code chunk in one function
clean_function = function(x) {
  line = strsplit(x, "[; , =]") [[1]]
  a = line[-(1:10)] %>% matrix(ncol=4, byrow=TRUE)  
  b = line[c(2,4,6,7,8,10)] %>% matrix(ncol=6, nrow=nrow(a), byrow=TRUE) 
  cbind(b,a)
}

#Test clean_function with row 1 in clean_offline
lapply(clean_offline[1], clean_function) [[1]] %>% view()

```

```{r}
#This code chunk will use clean_function for all rows in clean_offline and rbind them together
```

# Raw data cleaning
```{r}

```

```{r}
# Plot the orientation of the measurement device
#plot(ecdf(clean_offline$orientation))
```
